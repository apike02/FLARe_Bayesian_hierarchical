---
title: "Hierachal computational modelling - FLARe"

output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: true
    number_sections: true
    highlight: monochrome
    theme: cerulean
    code_folding: show
     
  html_notebook:
    theme: cerulean
    toc: yes
   
---

# Introduction {.tabset}

Lab book for analyses using hierachal computational modelling to identify paramters that define the best model of learning as it applies to fear conditioning acquisition and extinction using FLARe fear conditioning data. 
Long abstract, justification and analysis plan found in prelim manuscript [here]([https://docs.google.com/document/d/1JhVCf0jlXFwXYQ2kjS3fpl7mYexDcULn7L1ZgJ6Nolw/edit?usp=sharing])

In short:

## Aims    
     
1.  Identify model of learning based on a priori hypotheses that best fits the trajectories of fear relevant learning in our FLARe dataset
      + Use all first week data from Validation, app TRT, lab TRT, Pilot, Headphones (n = 223 after exclusions)
      + Include Acquisition, extinction (trajectories representing fear learning and treatment)
      + Identify parameters that define these trajectories
          + e.g. Learnign rate, plateau, first ambiguous trial etc.
          
2.  Cross validate best fitting model in TEDS data

3.  Are these parameters associated with other emasures of indsividual differences in our datasets?
      + Personality (Neuroticism)
      + Current anxiety symptoms (GAD-7) - equivalent of baseline symptoms (Chris + Meg analyses)
      + Lifetime / trait anxiety (STAI / ASI - FLARe analyses)
      + Current depression symptoms (PHQ-9) -  equivalent of baseline symptoms (Chris + Meg analyses)
      + Interpretation biases (IUS, ASSIQ - FLARe analyses)
      + SES (Meg IAPT: benefits, employment etc) 
      + Gender (Meg analyses)
      + Emotion regulation profile (potentially LCA based?)


## Impact and relevance

```
Evidence from both human (Richter et al., 2012) and rodent (Galatzer-Levy, Bonanno, Bush, & LeDoux, 2013) studies suggest that trajectories of how we learn and extinguish fear differ between individuals. Different trajectories of fear and extinction have also been found using fear conditioning studies (e.g. Duits et al., 2016), a good model for the learning of, and treatment for, fear and anxiety disorders. It is likely that these trajectories of fear extinction might predict outcomes in exposure-based cognitive behavioural therapy (Kindt, 2014). 
 
Identifying parameters that predict individual trajectories of fear learning and extinction will enable us to harness fear conditioning data more effectively to aid in understanding mechanisms underlying the development of and treatment for anxiety disorders. With more accurate models of these processes, the potential to use fear conditioning paradigms to predict those most at risk of developing an anxiety disorder, and those who might respond best to exposure-based treatments, greatly improves.
```

## Useful references

[Sutton and Barto Reinforcement Learning](http://incompleteideas.net/book/RLbook2018.pdf) - Textbook on reinforcement learning   
[Anxiety promotes memory for mood-congruent faces but does not alter loss aversion (Charpentier...Robinson, 2015)](https://www.nature.com/articles/srep24746.pdf) - Good example of a sensitivity learning parameter    
[Hypotheses About the Relationship of Cognition With Psychopathology Should be Tested by Embedding Them Into Empirical Priors (Moutoussist et al., 2018)](https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02504/full) - Including variables of interest (e.g. anxiety) in the model    



## Analysis plan 

1.  Define set of a priori models moving from simple to more complex   
      + Some paramters to include: 
        + Rate of learning (sometimes with punishment reinforcement)
        + Sensitivity to punishment
        + Pre-existing anxiety
        + SES? Gender?    
        

        
2.  Run each model and compare fit in FLARe pre TEDS data
      + Use Log likelihood and BIC etc.    
      
      
3.  Select best fitting model   


4.  Extract individual data for learning parameters from this model and see what factors best predict it
      + Anxiety (if anxiety isnt best as part of the model)
      + Interpretation biases
      + Tolerance of uncertanty
      + Cognitive emotional control
      + emotional attentional control 
      + SES?
      + Gender?    
      

4.  Run all models again in FLARe TEDS
      + Decide if the same model best fits the data again.
      + See if we get similar results from the parameter prediction   
      
    


Will use a combination of `R.Version(3.5.1)`, `RStan (Version 2.18.2, GitRev: 2e1f913d3ca3)` and `hBayesDM package in R (3.5.1)` [Ahn, W.-Y., Haines, N., & Zhang, L. (2017). Revealing neuro-computational mechanisms of reinforcement learning and decision-making with the hBayesDM package. Computational Psychiatry, 1, 24-57.](https://doi.org/10.1162/CPSY_a_00), which uses RStan

# Analyses {.tabset}

## Preliminary 

### Set up

These use Alex Pikes RStan script with minor modification to make it punishment only to see if it runs. Testing that the approach works with the current data set up etc.  

The settings for the script are below, including stan chain paramters and directory set up.

```{r, echo=F,results=F}

#clears environment
rm(list=ls())

#testing is TRUE means runs with less of everything for speed
testing=FALSE

# directories
workingdir='/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Modelling'
scriptdir='/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Scripts'
datadir='/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/LatentGrowth/Datasets/'

# stan parameters

chain_iter=2e4 # number of iterations for each chain inc. warmup (half)
if (testing==TRUE) chain_iter=2e3
chain_n=4 #4 chains
if (testing==TRUE) chain_n=1

```

This loads the libraries and source files needed to run this script, and sets up RStan

```{r, echo = F,results='hide',message=F}

# libraries and source files 
library('MASS')
library('boot')
library('dplyr')
library('reshape')
library('tidyr')
library('rstan') 
library('loo')
library('data.table')

#options for RSTAN
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
Sys.setenv(LOCAL_CPPFLAGS = '-march=native')
Sys.getenv('LOCAL_CPPFLAGS') #should say '-march=native'

#functions (if and when relevant and added)
# source('/Users/kirstin/Dropbox/SGDP/Function_library/<<function script name>>')
source('/Users/kirstin/Dropbox/SGDP/Function_library/not_in.R') # Not in %!in% function

```

### Try RStan

See if the basic punishment only learning model for the CS+ and CS- works with the FLARe master data

#### Run the 8schools check

From the [rstan github](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started)

This is to check that all is compiling and working and to give and idea of data format etc.


```{r}



```
#### Adjust dataframe

load in the week 1 app and lab data for FLARe pilot, TRT and headphones studies. Make it long form.

Try with acquisition data first. This is formatted with no column names, with no missing data.

Derive the n parameter for both files and check these match

```{r}

stanname='punish_only.stan'
minus_name <- 'bayes_acq_minus.csv'
plus_name <- "bayes_acq_plus.csv"

stanfile <- file.path(scriptdir, stanname)
minusfile <- file.path(datadir,minus_name)
plusfile <- file.path(datadir,plus_name)


minus <- fread(minusfile,data.table=F)
plus <-fread(plusfile,data.table=F)

nacqm <- dim(minus)[1]
nacqp <- dim(plus)[1]


if (nacqm == nacqp) {
  print('subject number match')
  nacq <- nacqm
  
  print(paste('nacq set to',nacq,sep=" "))
} else {
  print('WARNING: subject number does not match. Check master dataset')
}

# check the file format is ok

minus[1:2,]
plus[1:2,]

```


The expectancy rating datasets look like they are formatted fine.

Now will ensure trials and subject number and data references are correct in the rstan punishment only model file. 

This directs to my local machine here 

/Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Scripts and is linked to the github [repository here]()

** Note to self** add in bash to push to github when I change this script.


```{bash}


echo "// The 'data' block list all input variables that are given to Stan from R. You need to specify the size of the arrays
data {
  int ntrials;  // number of trials per participant; "int" means that the values are integers
  int nsub;     // number of subjects
  int punishA[ntrials,nsub];     // shape A associated with punishment; if lost when chose shape A
  int rating[ntrials,nsub];     // expectancy rating 0-9
  int includeTrial[ntrials];     // whether the data from this trial should be fitted (0 for trials to exclude)
}


// The 'parameters' block defines the parameter that we want to fit
parameters {
  // Stan syntax explanation:
  // real : parameters are real numbers
  // <lower=0,upper=1> : parameter is in the range of 0 to 1
  // alpha : name of the parameter
  // [nsub,2] : size of the parameter (number of rows, number of columns)
  // Group level parameters
  real<lower=0,upper=1> alpha_mu; // group level learning rate mean - pos neg
  real<lower=0> alpha_sd; // group level learning rate sd
  real<lower=0> beta_mu; // group level mean for temperature
  real<lower=0> beta_sd; // group level sd for temperature
  // Single subject parameters
  real<lower=0,upper=1> alpha[nsub]; // learning rate - separate learning rates for positive and negative
  real<lower=0> beta[nsub] ;   // temperature (i.e. how consistent choices are); one per participant
}

// This block runs the actual model
model {
  // temporary variables that we will compute for each person and each trial
  real QA[ntrials,nsub];  //Q value of shape A
  real QB[ntrials,nsub]; // Q value of shape B
  real deltaA[ntrials-1,nsub]; // prediction error for shape A
  real deltaB[ntrials-1,nsub];    // prediction error for shape B


  // Priors
  // as no prior for alpha is defined, it implicitly becomes the range it is given in the parameters block, i.e. from 0 to 1
  //  betawin1 ~ normal(0,1); //made this 10 as generally larger in this task

  // Priors for the individual subjects are the group:
  for (p in 1:nsub){
    alpha[p] ~ normal(alpha_mu,alpha_sd);
    beta[p]  ~ normal(beta_mu,beta_sd);
  }


  // The learning model: the aim is to define how the input data (i.e. the reward outcomes, the reward magnitudes) and parameters relate to the behavior
  // The basic structure of the model is exactly as in Matlab before:
  // The first lines define the learning of reward probabilities, then these are combined with magnitudes to give utilities
  // Then the choice utilities are linked to the actual choice using a softmax function
  for (p in 1:nsub){ // run the model for each subject
    // Learning
    QA[1,p] = 0; // first trial, best guess is that values are at 0
    QB[1,p] = 0;
    for (t in 1:ntrials-1){
      deltaA[t,p] = (punishA[t,p]) - QA[t,p]; // prediction error for A
      deltaB[t,p] = (1-punishA[t,p])- QB[t,p]; // prediction error for B
      QA[t+1,p] = QA[t,p] + alpha[p] * deltaA[t,p]; // Q learning for A
      QB[t+1,p] = QB[t,p] + alpha[p] * deltaB[t,p]; // should delta be same in both cases?
    }


    // Decision - combine predictions of punish probability with magnitudes
    for (t in 1:ntrials){
      if (includeTrial[t]==1){ // if  we want to fit the trial (we don't have missing responses)

        // Compare the choice probability (based on the utility) to the actual choice
        // See the handout for the syntax of the bernoulli_logit function
        // equivalently we could have written (as we have done previously in Matlab; but this runs a bit less well in Stan).:
        // ChoiceProbability1[it,is] = 1/(1+exp(beta[is]*(util2[it,is]-util1[it,is]))); // the softmax is an 'inv_logit'
        // opt1Chosen[it,is] ~ bernoulli(ChoiceProbability1[it,is]);
        // choices[t,p] ~ (exp(QA[t,p]/beta[p])/((exp(QA[t,p]/beta[p])+(QB[t,p]/beta[p]); // could do using bernoulli_logit
        // need to decide what distribution works best here with expectancy ratings
         rating[t,p] ~ bernoulli(exp(QA[t,p]/beta[p])/(exp(QA[t,p]/beta[p])+exp(QB[t,p]/beta[p])));
      }
    }
  }
}" >> /Users/kirstin/Dropbox/SGDP/FLARe/FLARe_MASTER/Projects/Hierachal_modelling/Scripts/punish_only.stan
   
   
```




```{r}

# colnames(simulated_data)<- c('study','pat/con','id','trial','reward','pun','choices')
# 
# rm(rewardA,punA,choices)
# 
# simulated_data_Chase<-subset(simulated_data,simulated_data$study==1) #Chase data
# 
# rewardA <- select(simulated_data_Chase,c('id','trial','reward')) %>% spread(id, reward, fill = 0)
# rewardA$trial <- NULL
# punishA <- select(simulated_data_Chase,c('id','trial','pun')) %>% spread(id, pun, fill = 0)
# punishA$trial <- NULL
# choices <- select(simulated_data_Chase,c('id','trial','choices')) %>% spread(id, choices, fill = 0)
# choices$trial <- NULL
# 
# Chase_data<-list(ntrials=ntrials,nsub=nsub_Chase,includeTrial = rep(1,ntrials),  rewardA=rewardA,punishA=punishA,choices=choices)
# 
# Chase_fit <- stan(file = stanfile, data = Chase_data, iter=chain_iter, chains = chain_n) #add working dir?
# save(Chase_fit, file=file.path(datadir,'Chase_fit'))
# 
# traceplot(Chase_fit,'lp__')
# 
# # draws_Chase<- extract(Chase_fit)
# summary_Chase<- summary(Chase_fit)
# 
# Chase_loglike<- extract_log_lik(Chase_fit, parameter_name = "loglik", merge_chains = TRUE)
# 
# loo(Chase_loglike)
# 
# overall_summary<-summary_Chase$summary #summary of all chains merged
# 
# #puts output in form for correlations
# estimated_Chase_output<- matrix(data=NA, nrow <- nsub_Chase, ncol<- 6)
# rownames<-paste('alpha[',1:nsub_Chase,',1]',sep='')
# estimated_Chase_output[,1] <- overall_summary[c(rownames),'mean']
# rownames<-paste('alpha[',1:nsub_Chase,',1]',sep='')
# estimated_Chase_output[,2] <- overall_summary[c(rownames),'sd']
# rownames<-paste('alpha[',1:nsub_Chase,',2]',sep='')
# estimated_Chase_output[,3] <- overall_summary[c(rownames),'mean']
# rownames<-paste('alpha[',1:nsub_Chase,',2]',sep='')
# estimated_Chase_output[,4] <- overall_summary[c(rownames),'sd']
# rownames<-paste('beta[',1:nsub_Chase,']',sep='')
# estimated_Chase_output[,5] <- overall_summary[c(rownames),'mean']
# rownames<-paste('beta[',1:nsub_Chase,']',sep='')
# estimated_Chase_output[,6] <- overall_summary[c(rownames),'sd']
# 
# #for positive learning rate
# cor.test(c(Chase_awin_pat,Chase_awin_con),estimated_Chase_output[,1]) #correlation
# lm(c(Chase_awin_pat,Chase_awin_con)~estimated_Chase_output[,1]) #regression equation
# plot(c(Chase_awin_pat,Chase_awin_con),estimated_Chase_output[,1]) #plot
# 
# #for negative learning rate
# cor.test(c(Chase_aloss_pat,Chase_aloss_con),estimated_Chase_output[,3])
# lm(c(Chase_aloss_pat,Chase_aloss_con)~estimated_Chase_output[,3])
# plot(c(Chase_aloss_pat,Chase_aloss_con),estimated_Chase_output[,3])
# 
# #for beta
# cor.test(c(Chase_beta_pat,Chase_beta_con),estimated_Chase_output[,5])
# lm(c(Chase_beta_pat,Chase_beta_con)~estimated_Chase_output[,5])
# plot(c(Chase_beta_pat,Chase_beta_con),estimated_Chase_output[,5])

```








